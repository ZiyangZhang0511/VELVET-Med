vision_encoder:
    input_size: [1, 96, 96, 96] # [C, H, W, D]
    name: "swinvit"
    swinvit:
        in_chans: 1
        embed_dim: 48
        window_size: 7
        patch_size: 2
        depths: [2, 8, 8, 8]
        num_heads: [4, 8, 16, 32]
        mlp_ratio: 4.0
        qkv_bias: True
        drop_rate: 0.0
        attn_drop_rate: 0.0
        drop_path_rate: 0.0
        norm_layer: "nn.LayerNorm"
        patch_norm: False
        use_checkpoint: True
        spatial_dims: 3
        downsample: "merging"
        use_v2: False
        pretrained_ckpt: ""

text_model:
    # "emilyalsentzer/Bio_ClinicalBERT" or "microsoft/BiomedVLP-CXR-BERT-general"
    # pretrained_weights: "microsoft/BiomedVLP-CXR-BERT-general"
    name: "sent_bert" # or base_bert
    hidden_size: 768
    intermediate_size: 3072
    max_position_embeddings: 512
    layer_norm_eps: 1.0e-12
    hidden_dropout_prob: 0.1
    num_hidden_layers: 18
    add_cross_attention: False
    chunk_size_feed_forward: 256
    is_decoder: False
    num_attention_heads: 6
    attention_probs_dropout_prob: 0.1
    hidden_act: "gelu"
    output_attentions: False
    output_hidden_states: True
    use_return_dict: True
    use_cache: False
    # mlm_probability: 0.15
    
    # pretrained_ckpt: ""
    # pretrained_ckpt: "./checkpoints/official_ckpts/bert_base_uncased.pth" 
    # pretrained_ckpt: "./checkpoints/official_ckpts/biomedvlp-cxr-bert-general.bin"

    layer_aggregate_fn: "sum" # or "mean"
    report_aggregate_fn: "none" # "sum" or "mean"
    sentence_aggregate_fn: "none" # "sum" or "mean"
    word_aggregate_fn: "none" # "sum" or "mean"

    # layer_for_txt_ssl: 6
    num_decoder_layers: 6

tokenizer:
    base_type: "microsoft/BiomedVLP-CXR-BERT-general" # cls_token_id: 2; sep_token_id: 3; mask_token_id: 4;
    max_len_report: 512
    max_len_sentence: 200
    max_num_sentences: 50
    sentence_modeling: False


pretrained_ckpt: "./checkpoints/visiontext_topitc_mmssl_BtSv/vl_ssl-swinvit-m3d_cap-dr1.0-E26-best/pytorch_model.bin"



freeze:
    vision_encoder: True
    text_encoder: True
    mm_adapter: False
    mm_encoder: False
    

downstream_task:
    task_type: "report_gen"  # choose from "cls_vqa_yn", "close_vqa_yn", "open_vqa_yn", "close_vqa_mc", "open_vqa_mc"
    txt_hidden_size: 768
    llm:
        hidden_size: 4096
        model_id: "ContactDoctor/Bio-Medical-Llama-3-8B"
        access_token: "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"
        max_length: 750
        min_length: 1
        rank: 8

        gen_max_length: 512
        gen_min_length: 1

        # {'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>', 'pad_token': '<|eot_id|>'}
        # bos_token_id: 128000, eos_token_id: 128009, pad_token_id: 0

        